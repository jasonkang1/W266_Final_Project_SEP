# W266_Final_Project_Sentence Encoding Pre-screening for Q%A

We propose a conceptual design, Sentence Embedding Prescreening (SEP), to be used in conjunction with any word token based Q&A models to improve the overall efficiency and reduce hardware constrains. Our concept of the light add-on model, SEP, aims to identify the particular sentence that contains the answer, in order to significantly reduce the amount of the input to the subsequent BERT based models. 

It should be noted that during our subsequent research, we realized that a similar model was presented in paper “Efficient and Robust Question Answering from Minimal Context over Documents”. However, it has a very different focus and adopts a totally different architecture.

We developed 4 different prototypes and conducted 4 more additional trials based on best performing model in order to prove this conecept.

- We present the Best performing model in this Git Repo
- Other models and trials can be found at https://drive.google.com/drive/folders/1DgozEWeXoIO6mXVy1dAHqSf3r8UOnAOD?usp=sharing
