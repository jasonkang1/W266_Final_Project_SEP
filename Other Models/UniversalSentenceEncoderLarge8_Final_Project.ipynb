{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UniversalSentenceEncoderLarge8_Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBONmCoioKUN",
        "colab_type": "text"
      },
      "source": [
        "# Sentence Picker Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l7F4JWIWeT3",
        "colab_type": "text"
      },
      "source": [
        "## Load preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1_ANk8zdzcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdrive_project_pathname = '/My Drive/w266/SQuad/UniversalSentenceEncoder/'  #@param {type: \"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swv-Aiyxd7XK",
        "colab_type": "code",
        "outputId": "4657e054-0bf9-4d7d-9419-4cb4145c7c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import os.path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the current user's Google Drive\n",
        "GOOGLE_DRIVE_MOUNT_POINT = \"/content/drive\"\n",
        "print(\"Mounting Google Drive beneath %s\" % GOOGLE_DRIVE_MOUNT_POINT)\n",
        "drive.mount(GOOGLE_DRIVE_MOUNT_POINT, force_remount = True)\n",
        "\n",
        "# Build the pathname to the project's folder residing beneath the current user's Google Drive\n",
        "if not gdrive_project_pathname.startswith(\"/\"):\n",
        "  gdrive_project_pathname = \"/\" + gdrive_project_pathname\n",
        "abs_project_pathname = GOOGLE_DRIVE_MOUNT_POINT + gdrive_project_pathname\n",
        "print(\"Project folder: %s\" % gdrive_project_pathname)\n",
        "\n",
        "# Check that the subdirectories anticipated beneath the Google Drive project folder exist\n",
        "# by checking for the presence of the DO_NOT_DELETE.txt file\n",
        "for subfolder in [\"data\", \"py\"]:\n",
        "    if not os.path.exists(abs_project_pathname + \"/\" + subfolder + \"/DO_NOT_DELETE.txt\"):\n",
        "        raise FileNotFoundError(\"Required subfolder '\" + subfolder + \"' does not exist beneath the Google Drive project folder\")\n",
        "print(\"Project subfolders successfully verified\")\n",
        "\n",
        "abs_data_pathname = abs_project_pathname + \"data\"\n",
        "abs_py_pathname = abs_project_pathname + \"py/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounting Google Drive beneath /content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Project folder: /My Drive/w266/SQuad/UniversalSentenceEncoder/\n",
            "Project subfolders successfully verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgVAkxd1rUji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "# Python resources developed for this project\n",
        "sys.path.append(abs_py_pathname)\n",
        "import util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DW0_9eLdqt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow tensorflow-datasets matplotlib\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "tf.enable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0OowSDBduJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import tensorflow_hub as hub\n",
        "# disable warnings:\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "# import os\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIa_DSMIzzfV",
        "colab_type": "code",
        "outputId": "e1abd545-448e-4438-81e0-a4d5544b6235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Version checks\n",
        "import importlib\n",
        "def version_greater_equal(v1, v2):\n",
        "    for x, y in zip(v1.split('.'), v2.split('.')):\n",
        "        if int(x) != int(y):\n",
        "            return int(x) > int(y)\n",
        "    return True\n",
        "    \n",
        "def version_check(libname, min_version):\n",
        "    m = importlib.import_module(libname)\n",
        "    print (\"%s version %s is \" % (libname, m.__version__))\n",
        "    print (\"OK\"\n",
        "           if version_greater_equal(m.__version__, min_version) \n",
        "           else \"out-of-date. Please upgrade!\")\n",
        "    \n",
        "version_check(\"tensorflow\", \"1.10\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version 2.2.0-rc2 is \n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiHsqrald0JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_data=pd.read_pickle('/gdrive/My Drive/Colab Notebooks/SQuad/data/train_v1_pd.pkl')\n",
        "train_data=pd.read_pickle(abs_data_pathname + '/train_v2_pd.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1tBr02J5EuL",
        "colab_type": "code",
        "outputId": "9789402f-d4b6-4826-fda5-23d281545ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answers</th>\n",
              "      <th>Start</th>\n",
              "      <th>Target</th>\n",
              "      <th>Context_length</th>\n",
              "      <th>Input</th>\n",
              "      <th>Expectation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[5733be284776f41900661182]</td>\n",
              "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
              "      <td>[To whom did the Virgin Mary allegedly appear ...</td>\n",
              "      <td>[Saint Bernadette Soubirous]</td>\n",
              "      <td>[515]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>7</td>\n",
              "      <td>[To whom did the Virgin Mary allegedly appear ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5733be284776f4190066117f]</td>\n",
              "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
              "      <td>[What is in front of the Notre Dame Main Build...</td>\n",
              "      <td>[a copper statue of Christ]</td>\n",
              "      <td>[188]</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>7</td>\n",
              "      <td>[What is in front of the Notre Dame Main Build...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[5733be284776f41900661180]</td>\n",
              "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
              "      <td>[The Basilica of the Sacred heart at Notre Dam...</td>\n",
              "      <td>[the Main Building]</td>\n",
              "      <td>[279]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>7</td>\n",
              "      <td>[The Basilica of the Sacred heart at Notre Dam...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[5733be284776f41900661181]</td>\n",
              "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
              "      <td>[What is the Grotto at Notre Dame?]</td>\n",
              "      <td>[a Marian place of prayer and reflection]</td>\n",
              "      <td>[381]</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>7</td>\n",
              "      <td>[What is the Grotto at Notre Dame?, Architectu...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[5733be284776f4190066117e]</td>\n",
              "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
              "      <td>[What sits on top of the Main Building at Notr...</td>\n",
              "      <td>[a golden statue of the Virgin Mary]</td>\n",
              "      <td>[92]</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>7</td>\n",
              "      <td>[What sits on top of the Main Building at Notr...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           ID  ...                               Expectation\n",
              "0  [5733be284776f41900661182]  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
              "1  [5733be284776f4190066117f]  ...  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
              "2  [5733be284776f41900661180]  ...  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
              "3  [5733be284776f41900661181]  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
              "4  [5733be284776f4190066117e]  ...  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXFSepECsaMX",
        "colab_type": "text"
      },
      "source": [
        "## **Setting Hyper Parameter**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lq1RITuUdFs_",
        "colab": {}
      },
      "source": [
        "# Hyper Parameter\n",
        "embedding_model=\"https://tfhub.dev/google/universal-sentence-encoder-large/5\" #\"https://tfhub.dev/google/universal-sentence-encoder-qa/3\" #\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\"\n",
        "Embedding_dimension=512 #250 # Must be consistent with the embedding model chosen\n",
        "Embedding_expansion=1024\n",
        "Layer_num=8\n",
        "num_heads=8\n",
        "batch_size=32 #64 #32\n",
        "embed_training=False\n",
        "assert Embedding_expansion % num_heads == 0\n",
        "learning_rate=0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzVNp6ualzrE",
        "colab_type": "text"
      },
      "source": [
        "## Define model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxXP4-43KU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, embedding_model_link, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding = hub.KerasLayer(embedding_model_link,input_shape=[],trainable=True)\n",
        "    \n",
        "    self.enc_layers = [util.EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "        \n",
        "  def call(self, x, training,mask=None):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    out_list=None\n",
        "    for batch in x:\n",
        "        temp=self.embedding(batch)\n",
        "\n",
        "        temp=temp[tf.newaxis,...]\n",
        "        if out_list is None:\n",
        "            out_list=temp\n",
        "        else:\n",
        "            out_list=tf.concat([out_list,temp],axis=0)\n",
        "    x=out_list # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training,mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1hXkDTS38bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mymodel(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,embedding_model_link,rate=0.1):\n",
        "    super(Mymodel, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, embedding_model_link, rate)\n",
        "    \n",
        "    self.output_layer1 = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    self.d_model=d_model\n",
        "    \n",
        "    \n",
        "  def call(self, para, training, mask=None):\n",
        "\n",
        "    enc_output = self.encoder(para,training,mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    sentence_num=enc_output.shape[-2]\n",
        "    \n",
        "    output=tf.reshape(enc_output,(-1,self.d_model))\n",
        "    \n",
        "    output=self.output_layer1(output)\n",
        "    output=tf.reshape(output,(-1,sentence_num))\n",
        "    \n",
        "    if mask is not None:\n",
        "        mask=tf.squeeze(mask,axis=[1,2])\n",
        "        output += (mask * -1e9)\n",
        "    output=output[:,1:]\n",
        "    output=tf.nn.softmax(output,axis=-1)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtIFjYUn4Krr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AnswerLocator=\"\"\n",
        "AnswerLocator=Mymodel(Layer_num,Embedding_dimension,num_heads,Embedding_expansion,embedding_model,0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRlL3z_zsrcX",
        "colab_type": "text"
      },
      "source": [
        "## Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oEM1S73qabd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Id3F_3sO6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn= tf.keras.losses.CategoricalCrossentropy()\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bne4gfnX5Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# @tf.function()#input_signature=train_step_signature)\n",
        "def train_step(context, target,mask=None):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = AnswerLocator(context,True,mask)\n",
        "    loss = loss_fn(target, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, AnswerLocator.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, AnswerLocator.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(target, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Tv5VLDpF4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check Point setup:\n",
        "checkpoint_path = \"/gdrive/My Drive/w266/SQuad/UniversalSentenceEncoder/checkpoint/UniversalSentenceEn/Large/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(AnswerLocator=AnswerLocator,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "# if ckpt_manager.latest_checkpoint:\n",
        "#   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#   print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi_KCMqphFE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @tf.function\n",
        "def eval_step(Inputs,Validation):\n",
        "  correct=0\n",
        "  count=0\n",
        "  predictions = AnswerLocator(Inputs,False,None)\n",
        "  for n,prediction in enumerate(predictions):\n",
        "      count+=1\n",
        "      \n",
        "      result=np.argmax(prediction)\n",
        "      \n",
        "      if result in Validation:\n",
        "          correct+=1\n",
        "  return correct,count\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJELBeq2elHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_data=pd.read_pickle(abs_data_pathname + '/dev_v1_pd.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RddNZSTOhwhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_result():\n",
        "  start = time.time()\n",
        "  \n",
        "  dev_correct=0\n",
        "  dev_count=0\n",
        "  \n",
        "  dev_index=np.arange(len(dev_data))\n",
        "\n",
        "  for batch,index in enumerate(dev_index):\n",
        "    Inputs=util.get_value_ts(dev_data,[index],'Input')\n",
        "    Validation=dev_data.iloc[index]['Validation']\n",
        "    \n",
        "    correct,count=eval_step(Inputs,Validation)\n",
        "    dev_correct+=correct\n",
        "    dev_count+=count\n",
        "    \n",
        "  print ('Accuracy {:.4f}'.format(dev_correct/dev_count))\n",
        "\n",
        "  print ('Time taken: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex4Tlc0qirSZ",
        "colab_type": "text"
      },
      "source": [
        "## Execute Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMoQnNvpiNd9",
        "colab_type": "code",
        "outputId": "a648b053-0ef0-4774-8d79-c936f07a4ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "EPOCHS=2\n",
        "batch_list = []\n",
        "loss_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  train_index=util.shuffle_data(train_data,batch_size)\n",
        "\n",
        "\n",
        "  for batch,index in enumerate(train_index):\n",
        "    Inputs=util.get_value_ts(train_data,index,'Input')\n",
        "    \n",
        "    target=util.get_value_ts(train_data,index,'Target')\n",
        "    \n",
        "    \n",
        "    mask=util.create_padding_mask(Inputs)\n",
        "    train_step(Inputs,target,mask)\n",
        "    \n",
        "    if batch % 200 == 0:\n",
        "      batch_list.append(batch)\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  \n",
        "  ckpt_save_path = ckpt_manager.save()\n",
        "  \n",
        "  # eval_result()\n",
        "  print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "  loss_list.append(train_loss.result())\n",
        "  accuracy_list.append(train_accuracy.result())\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.5935 Accuracy 0.3125\n",
            "Epoch 1 Batch 200 Loss 1.5716 Accuracy 0.2463\n",
            "Epoch 1 Batch 400 Loss 1.5499 Accuracy 0.2604\n",
            "Epoch 1 Batch 600 Loss 1.5115 Accuracy 0.2892\n",
            "Epoch 1 Batch 800 Loss 1.4565 Accuracy 0.3240\n",
            "Epoch 1 Batch 1000 Loss 1.3882 Accuracy 0.3701\n",
            "Epoch 1 Batch 1200 Loss 1.3200 Accuracy 0.4126\n",
            "Epoch 1 Batch 1400 Loss 1.2623 Accuracy 0.4473\n",
            "Epoch 1 Batch 1600 Loss 1.2122 Accuracy 0.4766\n",
            "Epoch 1 Batch 1800 Loss 1.1701 Accuracy 0.5008\n",
            "Epoch 1 Batch 2000 Loss 1.1326 Accuracy 0.5219\n",
            "Epoch 1 Batch 2200 Loss 1.0999 Accuracy 0.5393\n",
            "Epoch 1 Batch 2400 Loss 1.0724 Accuracy 0.5552\n",
            "Epoch 1 Batch 2600 Loss 1.0488 Accuracy 0.5687\n",
            "Saving checkpoint for epoch 1 at /gdrive/My Drive/w266/SQuad/UniversalSentenceEncoder/checkpoint/UniversalSentenceEn/Large/ckpt-1\n",
            "Epoch 1 Loss 1.0320 Accuracy 0.5777\n",
            "Time taken for 1 epoch: 9481.01419377327 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.6132 Accuracy 0.8438\n",
            "Epoch 2 Batch 200 Loss 0.5903 Accuracy 0.8030\n",
            "Epoch 2 Batch 400 Loss 0.5832 Accuracy 0.8039\n",
            "Epoch 2 Batch 600 Loss 0.5823 Accuracy 0.8038\n",
            "Epoch 2 Batch 800 Loss 0.5875 Accuracy 0.8018\n",
            "Epoch 2 Batch 1000 Loss 0.5845 Accuracy 0.8028\n",
            "Epoch 2 Batch 1200 Loss 0.5801 Accuracy 0.8041\n",
            "Epoch 2 Batch 1400 Loss 0.5802 Accuracy 0.8038\n",
            "Epoch 2 Batch 1600 Loss 0.5776 Accuracy 0.8043\n",
            "Epoch 2 Batch 1800 Loss 0.5784 Accuracy 0.8042\n",
            "Epoch 2 Batch 2000 Loss 0.5775 Accuracy 0.8042\n",
            "Epoch 2 Batch 2200 Loss 0.5772 Accuracy 0.8049\n",
            "Epoch 2 Batch 2400 Loss 0.5814 Accuracy 0.8038\n",
            "Epoch 2 Batch 2600 Loss 0.5834 Accuracy 0.8029\n",
            "Saving checkpoint for epoch 2 at /gdrive/My Drive/w266/SQuad/UniversalSentenceEncoder/checkpoint/UniversalSentenceEn/Large/ckpt-2\n",
            "Epoch 2 Loss 0.5842 Accuracy 0.8027\n",
            "Time taken for 1 epoch: 8740.213208198547 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5K7qMSOatt9",
        "colab_type": "code",
        "outputId": "fbd2a372-309a-42ec-bb58-64914995eff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "ckpt_save_path = ckpt_manager.save()\n",
        "print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                        ckpt_save_path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving checkpoint for epoch 2 at /gdrive/My Drive/w266/SQuad/UniversalSentenceEncoder/checkpoint/UniversalSentenceEn/Large/ckpt-3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m94jxNt0g1Yh",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep8DiTV9UGEM",
        "colab_type": "code",
        "outputId": "d83e1684-e313-41bd-cbd2-f1fe8c2397dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "eval_result()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8117\n",
            "Time taken: 998.7151756286621 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}