{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prototype 4 -- Universal Large + Beam2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JBONmCoioKUN","colab_type":"text"},"source":["# Sentence Picker Model"]},{"cell_type":"markdown","metadata":{"id":"4l7F4JWIWeT3","colab_type":"text"},"source":["## Load preprocessed data"]},{"cell_type":"code","metadata":{"id":"JAXEmaMFdQNF","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DW0_9eLdqt_","colab_type":"code","colab":{}},"source":["!pip install -q tensorflow tensorflow-datasets matplotlib\n","!pip install --upgrade tensorflow-gpu\n","!pip install tensorflow-hub\n","\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow.compat.v2 as tf\n","import tensorflow_hub as hub\n","\n","\n","import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","tf.enable_v2_behavior()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0OowSDBduJj","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import time\n","import tensorflow_hub as hub"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCe7aIA3jfgX","colab_type":"code","colab":{}},"source":["train_data=pd.read_pickle('/gdrive/My Drive/Colab Notebooks/NLP project stages/Prototype 4 -- Small Universal 8 layers/train_v1_pd.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2ivwLeoPLhr","colab_type":"code","colab":{}},"source":["def add_length(item):\n","    return len(item)\n","train_data['Context_length']=train_data['Context'].apply(add_length)\n","# train_data['Question_number']=train_data['Question'].apply(add_length)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFQ6ypI-IANY","colab_type":"code","colab":{}},"source":["def prepare_input(row):\n","    row['Input']=row['Question']+row['Context']\n","    row['Expectation']=[0.0]+list(row['Target'])\n","    return row\n","train_data=train_data.apply(prepare_input,axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BWm-Bd_17B8z","colab_type":"code","outputId":"b130f10c-e1b8-4799-e137-ff36c7481a52","executionInfo":{"status":"ok","timestamp":1586861332761,"user_tz":-480,"elapsed":150938,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":342}},"source":["train_data.tail(3)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Context</th>\n","      <th>Question</th>\n","      <th>Answers</th>\n","      <th>Start</th>\n","      <th>Target</th>\n","      <th>Context_length</th>\n","      <th>Input</th>\n","      <th>Expectation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>87596</th>\n","      <td>[5735d259012e2f140011a09f]</td>\n","      <td>[Kathmandu Metropolitan City (KMC), in order t...</td>\n","      <td>[With what Belorussian city does Kathmandu hav...</td>\n","      <td>[Minsk]</td>\n","      <td>[476]</td>\n","      <td>[0.0, 0.0, 1.0, 0.0]</td>\n","      <td>4</td>\n","      <td>[With what Belorussian city does Kathmandu hav...</td>\n","      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>87597</th>\n","      <td>[5735d259012e2f140011a0a0]</td>\n","      <td>[Kathmandu Metropolitan City (KMC), in order t...</td>\n","      <td>[In what year did Kathmandu create its initial...</td>\n","      <td>[1975]</td>\n","      <td>[199]</td>\n","      <td>[0.0, 1.0, 0.0, 0.0]</td>\n","      <td>4</td>\n","      <td>[In what year did Kathmandu create its initial...</td>\n","      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>87598</th>\n","      <td>[5735d259012e2f140011a0a1]</td>\n","      <td>[Kathmandu Metropolitan City (KMC), in order t...</td>\n","      <td>[What is KMC an initialism of?]</td>\n","      <td>[Kathmandu Metropolitan City]</td>\n","      <td>[0]</td>\n","      <td>[1.0, 0.0, 0.0, 0.0]</td>\n","      <td>4</td>\n","      <td>[What is KMC an initialism of?, Kathmandu Metr...</td>\n","      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               ID  ...                Expectation\n","87596  [5735d259012e2f140011a09f]  ...  [0.0, 0.0, 0.0, 1.0, 0.0]\n","87597  [5735d259012e2f140011a0a0]  ...  [0.0, 0.0, 1.0, 0.0, 0.0]\n","87598  [5735d259012e2f140011a0a1]  ...  [0.0, 1.0, 0.0, 0.0, 0.0]\n","\n","[3 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"pf_qTghHt0El","colab_type":"text"},"source":["## Setting up data pipeline"]},{"cell_type":"code","metadata":{"id":"4AkrJeprV706","colab_type":"code","colab":{}},"source":["def shuffle_data(dataframe,batch_size):\n","    batches=len(dataframe)//batch_size\n","    index=np.arange(batches*batch_size)\n","    np.random.shuffle(index)\n","    index=index.reshape(batches,batch_size)\n","    return index"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sq1dg6rIQmDh","colab_type":"code","colab":{}},"source":["def get_value_ts(dataframe,index,type):\n","    if type=='Input':\n","        return tf.cast(tf.ragged.constant(dataframe.iloc[index][type]).to_tensor(),dtype=tf.string)\n","    elif type=='Target':\n","        return tf.cast(tf.ragged.constant(dataframe.iloc[index][type]).to_tensor(),dtype=tf.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkgJmh-SRVWB","colab_type":"code","outputId":"20f3a835-0360-4ed8-d888-386b5862fb8b","executionInfo":{"status":"ok","timestamp":1585061953083,"user_tz":240,"elapsed":154083,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["get_value_ts(train_data,[3],'Input')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/ragged/ragged_tensor.py:1586: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=66, shape=(1, 8), dtype=string, numpy=\n","array([[b'What is the Grotto at Notre Dame?',\n","        b'Architecturally, the school has a Catholic character.',\n","        b\"Atop the Main Building's gold dome is a golden statue of the Virgin Mary.\",\n","        b'Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\".',\n","        b'Next to the Main Building is the Basilica of the Sacred Heart.',\n","        b'Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.',\n","        b'It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.',\n","        b'At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.']],\n","      dtype=object)>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"ZKzcnxbtP_iJ","colab_type":"code","colab":{}},"source":["def create_padding_mask(input_):\n","  seq = tf.cast(tf.math.equal(input_,''), tf.float32)\n","  \n","  # add extra dimensions to add the padding\n","  # to the attention logits.\n","  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mG1Um9_TQAlY","colab_type":"code","outputId":"b09e9c5f-e0a3-4476-96d6-d08494d8ac50","executionInfo":{"status":"ok","timestamp":1585061953085,"user_tz":240,"elapsed":154045,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["create_padding_mask(get_value_ts(train_data,[0,10,30],'Input'))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=140, shape=(3, 1, 1, 8), dtype=float32, numpy=\n","array([[[[0., 0., 0., 0., 0., 0., 0., 0.]]],\n","\n","\n","       [[[0., 0., 0., 0., 0., 0., 0., 1.]]],\n","\n","\n","       [[[0., 0., 0., 0., 0., 0., 0., 1.]]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"UXFSepECsaMX","colab_type":"text"},"source":["## **Setting Hyper Parameter**\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Lq1RITuUdFs_","colab":{}},"source":["# Hyper Parameter\n","embedding_model=\"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n","\n","Embedding_dimension=512 # Must be consistent with the embedding model chosen\n","Embedding_expansion=1024\n","Layer_num=8\n","num_heads=16\n","batch_size=32\n","embed_training=False\n","assert Embedding_expansion % num_heads == 0\n","learning_rate=0.0001"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NzVNp6ualzrE","colab_type":"text"},"source":["## Define model\n"]},{"cell_type":"markdown","metadata":{"id":"lvEkDBx1lcRk","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"1EtjJOxUA9ni","colab_type":"code","colab":{}},"source":["def scaled_dot_product_attention(q, k, v, mask=None):\n","  \"\"\"\n","  Args:\n","    q: query shape == (batch,seq_q, depth_expan) \n","    k: key shape == (seq_len_k, depth_expan) \n","    v: value shape == (seq_len_v, depth_expan)\n","    mask: Float tensor with shape broadcastable \n","          to (..., seq_len_q, seq_len_k). Defaults to None.\n","    \n","  Returns:\n","    output, attention_weights\n","  \"\"\"\n","\n","  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (batch, seq_len_q, seq_len_k) (4,3)\n","#   print(matmul_qk.shape)\n","  # scale matmul_qk\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","  \n","  # add the mask to the scaled tensor.\n","  if mask is not None:\n","    \n","    scaled_attention_logits += (mask * -1e9)  \n","\n","  # softmax is normalized on the last axis (seq_len_k) so that the scores\n","  # add up to 1.\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (batch, len_q, seq_len_k)\n","#   print(attention_weights.shape)\n","  output = tf.matmul(attention_weights, v)  # (batch, seq_len_q, depth_v)\n","#   print(output.shape)\n","#   print('Logit shape',attention_weights.shape)\n","  return output, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bs1TR2iMMDBR","colab_type":"code","colab":{}},"source":["# Test code for scaled dot-product attention:\n","def print_out(q, k, v):\n","  temp_out, temp_attn = scaled_dot_product_attention(\n","      q, k, v, None)\n","  print ('Attention weights are:')\n","  print (temp_attn)\n","  print ('Output is:')\n","  print (temp_out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNqDMN2IMSsQ","colab_type":"code","colab":{}},"source":["k = tf.constant([[10,0,0,],\n","                      [0,10,0,]], dtype=tf.float32)  # (2, 3)\n","\n","v = k\n","q = tf.constant([[0, 10, 0],[0, 0, 11],[20, 0, 11],[0, 0, 11]], dtype=tf.float32)  # (4, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7CVxXPk_iq_E","colab_type":"code","colab":{}},"source":["temp_k = tf.constant([[[10,0,0,],\n","                      [0,10,0,],\n","                      [0,0,10],\n","                      [0,0,10]],[[10,0,0,],\n","                      [0,10,0,],\n","                      [0,0,10],\n","                      [0,0,10]]], dtype=tf.float32)  # (2,4, 3)\n","\n","temp_q = tf.constant([[[0, 10, 0],[0, 0, 11]],[[0, 10, 0],[0, 0, 11]]], dtype=tf.float32)  # (2,2, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yuc44ptwy_ng","colab_type":"code","outputId":"8dc17037-9d27-46ce-8995-083e4a1df90a","executionInfo":{"status":"ok","timestamp":1585061954639,"user_tz":240,"elapsed":155514,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["print_out(temp_q, temp_k, temp_k)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Attention weights are:\n","tf.Tensor(\n","[[[8.4332738e-26 1.0000000e+00 8.4332738e-26 8.4332738e-26]\n","  [1.3108893e-28 1.3108893e-28 5.0000000e-01 5.0000000e-01]]\n","\n"," [[8.4332738e-26 1.0000000e+00 8.4332738e-26 8.4332738e-26]\n","  [1.3108893e-28 1.3108893e-28 5.0000000e-01 5.0000000e-01]]], shape=(2, 2, 4), dtype=float32)\n","Output is:\n","tf.Tensor(\n","[[[8.4332741e-25 1.0000000e+01 1.6866548e-24]\n","  [1.3108892e-27 1.3108892e-27 1.0000000e+01]]\n","\n"," [[8.4332741e-25 1.0000000e+01 1.6866548e-24]\n","  [1.3108892e-27 1.3108892e-27 1.0000000e+01]]], shape=(2, 2, 3), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5WS1VJi3NoRG","colab_type":"code","colab":{}},"source":["class MultiHeadSentenceAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model,num_heads):\n","    \n","    super(MultiHeadSentenceAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_model=d_model\n","    assert d_model % self.num_heads == 0\n","    \n","    self.depth = self.d_model // self.num_heads\n","\n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","    \n","    self.dense = tf.keras.layers.Dense(d_model)\n","        \n","  def split_heads(self, x,batch_size): # x question size(3,250)\n","    \"\"\"Split the last dimension into (num_heads, depth).\n","    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth) #()\n","    \"\"\"\n","    \n","    x = tf.reshape(x, (batch_size,-1, self.num_heads, self.depth)) \n","\n","    return tf.transpose(x, perm=[0, 2, 1, 3])           # (batch_size,3,5,50)\n","    \n","  def call(self, v, k, q, mask=None):\n","    batch_size = tf.shape(q)[0]\n","    q = self.wq(q)  # (seq_len, d_expan)     #(batch_size,3,250)\n","    \n","    k = self.wk(k)  # (seq_len, d_expan)     #(batch_size,4,250)\n","\n","    v = self.wv(v)  # (seq_len, d_expan)     #(batch_size,4,250)\n","\n","    \n","    q = self.split_heads(q,batch_size)  # (num_heads, seq_len_q, depth)    # (5,3,50)\n","    k = self.split_heads(k,batch_size)  # (num_heads, seq_len_k, depth)    # (5,4,50)\n","    v = self.split_heads(v,batch_size)  # (num_heads, seq_len_v, depth)    # (5,4,50)\n","    \n","    # scaled_attention.shape == (num_heads, seq_len_q, depth)\n","    # attention_weights.shape == (num_heads, seq_len_q, seq_len_k)\n","    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","    \n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","    concat_attention = tf.reshape(scaled_attention, (batch_size,-1, self.d_model))  # (batch_size, seq_len_q, d_expan)\n","    # print('Concat Attention size:',concat_attention.shape)\n","    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_expan)\n","    return output, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jt1w2B9hSqYY","colab_type":"code","outputId":"0ee21278-8248-4e77-bf02-2c15dd1ae6e2","executionInfo":{"status":"ok","timestamp":1585061954640,"user_tz":240,"elapsed":155487,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Test code for Multihead Sentence Attention\n","temp_mha = MultiHeadSentenceAttention(d_model=3, num_heads=3)\n","\n","\n","\n","temp_k = tf.constant([[[10,0,0,],\n","                      [0,10,0,],\n","                      [0,0,10],\n","                      [0,0,10]],[[10,0,0,],\n","                      [0,10,0,],\n","                      [0,0,10],\n","                      [0,0,10]]], dtype=tf.float32)  # (2,4, 3)\n","\n","temp_q = tf.constant([[[0, 10, 0],[0, 0, 11]],[[0, 10, 0],[0, 0, 11]]], dtype=tf.float32)  # (2,2, 3)\n","\n","out, attn = temp_mha(temp_k, temp_k, temp_q, mask=None)\n","out.shape, attn.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([2, 2, 3]), TensorShape([2, 3, 2, 4]))"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"oJ0BKiC2r4Ni","colab_type":"code","outputId":"1ca17034-dbb5-4ebd-d4c6-7194542f3792","executionInfo":{"status":"ok","timestamp":1585061954641,"user_tz":240,"elapsed":155470,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["print_out(out,temp_k,temp_k)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Attention weights are:\n","tf.Tensor(\n","[[[2.1095254e-20 5.7743830e-07 4.9999970e-01 4.9999970e-01]\n","  [5.2360864e-28 5.0496842e-12 5.0000000e-01 5.0000000e-01]]\n","\n"," [[2.1095254e-20 5.7743830e-07 4.9999970e-01 4.9999970e-01]\n","  [5.2360864e-28 5.0496842e-12 5.0000000e-01 5.0000000e-01]]], shape=(2, 2, 4), dtype=float32)\n","Output is:\n","tf.Tensor(\n","[[[2.1095254e-19 5.7743828e-06 9.9999943e+00]\n","  [5.2360866e-27 5.0496843e-11 1.0000000e+01]]\n","\n"," [[2.1095254e-19 5.7743828e-06 9.9999943e+00]\n","  [5.2360866e-27 5.0496843e-11 1.0000000e+01]]], shape=(2, 2, 3), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nlyo3m5Mgmkt","colab_type":"code","colab":{}},"source":["def point_wise_feed_forward_network(d_model, dff):\n","  return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","  ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lvkBFHh3j5n","colab_type":"code","colab":{}},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadSentenceAttention(d_model, num_heads)\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, training,mask=None):\n","\n","    attn_output, _ = self.mha(x, x, x,mask)  # (batch_size, input_seq_len, d_model)\n","    attn_output = self.dropout1(attn_output, training=training)\n","    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    return out2\n","\n","  \n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6aQ3Rxrxgu3n","colab_type":"code","outputId":"2df98567-3549-4367-eeaa-54576dd94576","executionInfo":{"status":"ok","timestamp":1585061954643,"user_tz":240,"elapsed":155430,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# Encoder Tesst code\n","temp_k = tf.constant([[[10,0,0,],\n","                      [0,10,0,],\n","                      [0,0,10],\n","                      [0,0,10]],[[10,0,0,],\n","                      [0,10,0,],\n","                      [0,0,10],\n","                      [0,0,10]]], dtype=tf.float32)  # (2,4, 3)\n","test_code=EncoderLayer(3,3,9,rate=0.1)\n","test_code(temp_k,training=False)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=689, shape=(2, 4, 3), dtype=float32, numpy=\n","array([[[ 1.2182857 ,  0.01281665, -1.2311022 ],\n","        [-1.0076237 ,  1.3631828 , -0.35555923],\n","        [-0.47795343, -0.9137027 ,  1.3916562 ],\n","        [-0.47795343, -0.9137027 ,  1.3916562 ]],\n","\n","       [[ 1.2182857 ,  0.01281665, -1.2311022 ],\n","        [-1.0076237 ,  1.3631828 , -0.35555923],\n","        [-0.47795343, -0.9137027 ,  1.3916562 ],\n","        [-0.47795343, -0.9137027 ,  1.3916562 ]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"fgn16htFkJHQ","colab_type":"code","colab":{}},"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, embedding_model_link, rate=0.1):\n","    super(Encoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    self.embedding = hub.KerasLayer(embedding_model_link,input_shape=[],trainable=True)\n","    \n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","  \n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","        \n","  def call(self, x, training,mask=None):\n","\n","    seq_len = tf.shape(x)[1]\n","    out_list=None\n","    for batch in x:\n","        temp=self.embedding(batch)\n","\n","        temp=temp[tf.newaxis,...]\n","        if out_list is None:\n","            out_list=temp\n","        else:\n","            out_list=tf.concat([out_list,temp],axis=0)\n","    x=out_list # (batch_size, input_seq_len, d_model)\n","    \n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","\n","    x = self.dropout(x, training=training)\n","    \n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, training,mask)\n","    \n","    return x  # (batch_size, input_seq_len, d_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fd6A2hDwltAA","colab_type":"code","outputId":"70113a22-c267-4792-fc6b-15f9af3486f4","executionInfo":{"status":"ok","timestamp":1585061957477,"user_tz":240,"elapsed":158229,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["temp_k = get_value_ts(train_data,[4,5],'Input')  # expect (2,2, 125)\n","\n","test_code=Encoder(4,250,5,500,embedding_model,)\n","encode_out=test_code(temp_k,False)\n","encode_out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([2, 12, 250])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"VvPVapCj-ows","colab_type":"code","colab":{}},"source":["class Mymodel(tf.keras.Model):\n","  def __init__(self, num_layers, d_model, num_heads, dff,embedding_model_link,rate=0.1):\n","    super(Mymodel, self).__init__()\n","\n","    self.encoder = Encoder(num_layers, d_model, num_heads, dff, embedding_model_link, rate)\n","    \n","    self.output_layer1 = tf.keras.layers.Dense(1)\n","    \n","    self.d_model=d_model\n","    \n","    \n","  def call(self, para, training, mask=None):\n","\n","    enc_output = self.encoder(para,training,mask)  # (batch_size, inp_seq_len, d_model)\n","    sentence_num=enc_output.shape[-2]\n","    \n","    output=tf.reshape(enc_output,(-1,self.d_model))\n","    \n","    output=self.output_layer1(output)\n","    output=tf.reshape(output,(-1,sentence_num))\n","    \n","    if mask is not None:\n","        mask=tf.squeeze(mask,axis=[1,2])\n","        output += (mask * -1e9)\n","    output=output[:,1:]\n","    output=tf.nn.softmax(output,axis=-1)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPhy6krZ-pH6","colab_type":"code","outputId":"f6613e63-c838-48c5-8989-34ee3d9f2a99","executionInfo":{"status":"ok","timestamp":1585061960164,"user_tz":240,"elapsed":160887,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# model test code\n","temp_k = get_value_ts(train_data,[4,5,6],'Input')  # expect (3,11, 250)\n","\n","test_code=Mymodel(4,250,5,500,embedding_model)\n","answer=test_code(temp_k,False)\n","answer.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([3, 11])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"zrmXuU-N58v9","colab_type":"code","colab":{}},"source":["AnswerLocator=\"\"\n","AnswerLocator=Mymodel(Layer_num,Embedding_dimension,num_heads,Embedding_expansion,embedding_model,0.05)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRlL3z_zsrcX","colab_type":"text"},"source":["## Training Setup\n"]},{"cell_type":"code","metadata":{"id":"3oEM1S73qabd","colab_type":"code","colab":{}},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_Id3F_3sO6I","colab_type":"code","colab":{}},"source":["loss_fn= tf.keras.losses.CategoricalCrossentropy()\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Bne4gfnX5Oy","colab_type":"code","colab":{}},"source":["\n","\n","# @tf.function()#input_signature=train_step_signature)\n","def train_step(context, target,mask=None):\n","  \n","  with tf.GradientTape() as tape:\n","    predictions = AnswerLocator(context,True,mask)\n","    loss = loss_fn(target, predictions)\n","\n","  gradients = tape.gradient(loss, AnswerLocator.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, AnswerLocator.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(target, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9Tv5VLDpF4o","colab_type":"code","colab":{}},"source":["#Check Point setup:\n","checkpoint_path = \"/gdrive/My Drive/Colab Notebooks/NLP project stages/Prototype 4 -- Small Universal 8 layers/Universal Large/\"\n","\n","ckpt = tf.train.Checkpoint(AnswerLocator=AnswerLocator,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pi_KCMqphFE6","colab_type":"code","colab":{}},"source":["# Evaluation function with Beam of top two answers\n","# @tf.function\n","def eval_step(Inputs,Validation):\n","  correct=0\n","  count=0\n","  predictions = AnswerLocator(Inputs,False,None)\n","  for n,prediction in enumerate(predictions):\n","      count+=1\n","      if len(prediction)<3:\n","        result=np.argmax(prediction)\n","        \n","        if result in Validation:\n","            correct+=1\n","      else:\n","        valid=Validation[0]\n","        if valid in np.argsort(prediction)[-2:]:\n","            correct+=1\n","\n","  return correct,count\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJELBeq2elHX","colab_type":"code","colab":{}},"source":["dev_data=pd.read_pickle('/gdrive/My Drive/Colab Notebooks/NLP project stages/Prototype 4 -- Small Universal 8 layers/dev_v1_pd.pkl')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wV-ielAb3cq2","colab_type":"code","outputId":"5278e72d-1fbd-47cb-bde7-94fd04fe7b89","executionInfo":{"status":"ok","timestamp":1586936284032,"user_tz":-480,"elapsed":25550,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":387}},"source":["dev_data.tail(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Context</th>\n","      <th>Question</th>\n","      <th>Answers</th>\n","      <th>Start</th>\n","      <th>Target</th>\n","      <th>Input</th>\n","      <th>Validation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10565</th>\n","      <td>[5737aafd1c456719005744fb]</td>\n","      <td>[The pound-force has a metric counterpart, les...</td>\n","      <td>[What is the metric term less used than the Ne...</td>\n","      <td>[kilogram-force, pound-force, kilogram-force (...</td>\n","      <td>[82, 4, 82, 82, 78]</td>\n","      <td>[[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [...</td>\n","      <td>[What is the metric term less used than the Ne...</td>\n","      <td>[0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>10566</th>\n","      <td>[5737aafd1c456719005744fc]</td>\n","      <td>[The pound-force has a metric counterpart, les...</td>\n","      <td>[What is the kilogram-force sometimes reffered...</td>\n","      <td>[kilopond, kilopond, kilopond, kilopond, kilop...</td>\n","      <td>[114, 114, 114, 114, 114]</td>\n","      <td>[[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [...</td>\n","      <td>[What is the kilogram-force sometimes reffered...</td>\n","      <td>[0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>10567</th>\n","      <td>[5737aafd1c456719005744fd]</td>\n","      <td>[The pound-force has a metric counterpart, les...</td>\n","      <td>[What is a very seldom used unit of mass in th...</td>\n","      <td>[slug, metric slug, metric slug, metric slug, ...</td>\n","      <td>[274, 267, 267, 267, 263]</td>\n","      <td>[[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...</td>\n","      <td>[What is a very seldom used unit of mass in th...</td>\n","      <td>[1, 1, 1, 1, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>10568</th>\n","      <td>[5737aafd1c456719005744fe]</td>\n","      <td>[The pound-force has a metric counterpart, les...</td>\n","      <td>[What seldom used term of a unit of force equa...</td>\n","      <td>[kip, kip, kip, kip, kip]</td>\n","      <td>[712, 712, 712, 712, 712]</td>\n","      <td>[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], [...</td>\n","      <td>[What seldom used term of a unit of force equa...</td>\n","      <td>[3, 3, 3, 3, 3]</td>\n","    </tr>\n","    <tr>\n","      <th>10569</th>\n","      <td>[5737aafd1c456719005744ff]</td>\n","      <td>[The pound-force has a metric counterpart, les...</td>\n","      <td>[What is the seldom used force unit equal to o...</td>\n","      <td>[sthène, sthène, sthène, sthène, sthène]</td>\n","      <td>[665, 665, 665, 665, 665]</td>\n","      <td>[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], [...</td>\n","      <td>[What is the seldom used force unit equal to o...</td>\n","      <td>[3, 3, 3, 3, 3]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               ID  ...       Validation\n","10565  [5737aafd1c456719005744fb]  ...  [0, 0, 0, 0, 0]\n","10566  [5737aafd1c456719005744fc]  ...  [0, 0, 0, 0, 0]\n","10567  [5737aafd1c456719005744fd]  ...  [1, 1, 1, 1, 1]\n","10568  [5737aafd1c456719005744fe]  ...  [3, 3, 3, 3, 3]\n","10569  [5737aafd1c456719005744ff]  ...  [3, 3, 3, 3, 3]\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"RddNZSTOhwhV","colab_type":"code","colab":{}},"source":["def eval_result():\n","  start = time.time()\n","  \n","  dev_correct=0\n","  dev_count=0\n","  \n","  dev_index=np.arange(len(dev_data))\n","\n","\n","  # inp -> portuguese, tar -> english\n","  for batch,index in enumerate(dev_index):\n","    Inputs=get_value_ts(dev_data,[index],'Input')\n","    # print('Context shape is ',context.shape,type(context))\n","    Validation=dev_data.iloc[index]['Validation']\n","    # print('Target shape is ',target.shape,type(target))\n","    \n","    correct,count=eval_step(Inputs,Validation)\n","    dev_correct+=correct\n","    dev_count+=count\n","    \n","  print ('Dev Accuracy {:.4f}'.format(dev_correct/dev_count))\n","\n","  print ('Time taken: {} secs\\n'.format(time.time() - start))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ex4Tlc0qirSZ","colab_type":"text"},"source":["## Execute Training"]},{"cell_type":"code","metadata":{"id":"RMoQnNvpiNd9","colab_type":"code","outputId":"4a109043-9833-4636-d07e-3aac3801cd1b","executionInfo":{"status":"ok","timestamp":1586953263081,"user_tz":-480,"elapsed":11380589,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","EPOCHS=2\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  train_index=shuffle_data(train_data,batch_size)\n","\n","\n","  for batch,index in enumerate(train_index):\n","    Inputs=get_value_ts(train_data,index,'Input')\n","    \n","    target=get_value_ts(train_data,index,'Target')\n","    \n","    \n","    mask=create_padding_mask(Inputs)\n","    train_step(Inputs,target,mask)\n","    \n","    if batch % 100 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","      \n","  \n","  ckpt_save_path = ckpt_manager.save()\n","  \n","#   eval_result()\n","  print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","  \n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 1.5197 Accuracy 0.3125\n","Epoch 1 Batch 100 Loss 1.5441 Accuracy 0.2559\n","Epoch 1 Batch 200 Loss 1.5409 Accuracy 0.2516\n","Epoch 1 Batch 300 Loss 1.5142 Accuracy 0.2759\n","Epoch 1 Batch 400 Loss 1.4895 Accuracy 0.2930\n","Epoch 1 Batch 500 Loss 1.4660 Accuracy 0.3074\n","Epoch 1 Batch 600 Loss 1.4352 Accuracy 0.3284\n","Epoch 1 Batch 700 Loss 1.4036 Accuracy 0.3531\n","Epoch 1 Batch 800 Loss 1.3629 Accuracy 0.3799\n","Epoch 1 Batch 900 Loss 1.3168 Accuracy 0.4081\n","Epoch 1 Batch 1000 Loss 1.2786 Accuracy 0.4321\n","Epoch 1 Batch 1100 Loss 1.2416 Accuracy 0.4549\n","Epoch 1 Batch 1200 Loss 1.2050 Accuracy 0.4754\n","Epoch 1 Batch 1300 Loss 1.1754 Accuracy 0.4927\n","Epoch 1 Batch 1400 Loss 1.1471 Accuracy 0.5087\n","Epoch 1 Batch 1500 Loss 1.1212 Accuracy 0.5234\n","Epoch 1 Batch 1600 Loss 1.0986 Accuracy 0.5362\n","Epoch 1 Batch 1700 Loss 1.0769 Accuracy 0.5484\n","Epoch 1 Batch 1800 Loss 1.0564 Accuracy 0.5597\n","Epoch 1 Batch 1900 Loss 1.0387 Accuracy 0.5698\n","Epoch 1 Batch 2000 Loss 1.0222 Accuracy 0.5792\n","Epoch 1 Batch 2100 Loss 1.0077 Accuracy 0.5877\n","Epoch 1 Batch 2200 Loss 0.9940 Accuracy 0.5952\n","Epoch 1 Batch 2300 Loss 0.9809 Accuracy 0.6022\n","Epoch 1 Batch 2400 Loss 0.9673 Accuracy 0.6092\n","Epoch 1 Batch 2500 Loss 0.9562 Accuracy 0.6153\n","Epoch 1 Batch 2600 Loss 0.9450 Accuracy 0.6209\n","Epoch 1 Batch 2700 Loss 0.9343 Accuracy 0.6266\n","Saving checkpoint for epoch 1 at /gdrive/My Drive/Colab Notebooks/NLP project stages/Prototype 4 -- Small Universal 8 layers/Universal Large/ckpt-1\n","Epoch 1 Loss 0.9300 Accuracy 0.6287\n","Time taken for 1 epoch: 8481.299294233322 secs\n","\n","Epoch 2 Batch 0 Loss 0.6305 Accuracy 0.8125\n","Epoch 2 Batch 100 Loss 0.4788 Accuracy 0.8391\n","Epoch 2 Batch 200 Loss 0.4812 Accuracy 0.8417\n","Epoch 2 Batch 300 Loss 0.4847 Accuracy 0.8413\n","Epoch 2 Batch 400 Loss 0.4838 Accuracy 0.8427\n","Epoch 2 Batch 500 Loss 0.4857 Accuracy 0.8429\n","Epoch 2 Batch 600 Loss 0.4875 Accuracy 0.8421\n","Epoch 2 Batch 700 Loss 0.4866 Accuracy 0.8424\n","Epoch 2 Batch 800 Loss 0.4835 Accuracy 0.8425\n","Epoch 2 Batch 900 Loss 0.4850 Accuracy 0.8424\n","Epoch 2 Batch 1000 Loss 0.4855 Accuracy 0.8431\n","Epoch 2 Batch 1100 Loss 0.4840 Accuracy 0.8432\n","Epoch 2 Batch 1200 Loss 0.4851 Accuracy 0.8426\n","Epoch 2 Batch 1300 Loss 0.4859 Accuracy 0.8418\n","Epoch 2 Batch 1400 Loss 0.4877 Accuracy 0.8416\n","Epoch 2 Batch 1500 Loss 0.4881 Accuracy 0.8417\n","Epoch 2 Batch 1600 Loss 0.4884 Accuracy 0.8415\n","Epoch 2 Batch 1700 Loss 0.4879 Accuracy 0.8413\n","Epoch 2 Batch 1800 Loss 0.4890 Accuracy 0.8412\n","Epoch 2 Batch 1900 Loss 0.4901 Accuracy 0.8411\n","Epoch 2 Batch 2000 Loss 0.4893 Accuracy 0.8413\n","Epoch 2 Batch 2100 Loss 0.4879 Accuracy 0.8417\n","Epoch 2 Batch 2200 Loss 0.4881 Accuracy 0.8414\n","Epoch 2 Batch 2300 Loss 0.4890 Accuracy 0.8411\n","Epoch 2 Batch 2400 Loss 0.4882 Accuracy 0.8411\n","Epoch 2 Batch 2500 Loss 0.4880 Accuracy 0.8413\n","Epoch 2 Batch 2600 Loss 0.4885 Accuracy 0.8412\n","Epoch 2 Batch 2700 Loss 0.4883 Accuracy 0.8414\n","Saving checkpoint for epoch 2 at /gdrive/My Drive/Colab Notebooks/NLP project stages/Prototype 4 -- Small Universal 8 layers/Universal Large/ckpt-2\n","Epoch 2 Loss 0.4880 Accuracy 0.8413\n","Time taken for 1 epoch: 8495.52578997612 secs\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m94jxNt0g1Yh","colab_type":"text"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"Ep8DiTV9UGEM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"a2c023c7-3a1d-4779-a463-8a37331d4ec0","executionInfo":{"status":"ok","timestamp":1586954151043,"user_tz":-480,"elapsed":887982,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}}},"source":["#Evaluation result without using beam 1epoch\n","def eval_step(Inputs,Validation):\n","  correct=0\n","  count=0\n","  predictions = AnswerLocator(Inputs,False,None)\n","  for n,prediction in enumerate(predictions):\n","      count+=1\n","      \n","      result=np.argmax(prediction)\n","      \n","      if result in Validation:\n","          correct+=1\n","  return correct,count\n","eval_result()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Dev Accuracy 0.8297\n","Time taken: 888.161276102066 secs\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4SeXVLoWoPII","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"b69c461a-3816-434c-f11c-54be22af0365","executionInfo":{"status":"ok","timestamp":1586955036687,"user_tz":-480,"elapsed":885654,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}}},"source":["#Evaluation result with beam K=2, 1epoch\n","def eval_step(Inputs,Validation):\n","  correct=0\n","  count=0\n","  predictions = AnswerLocator(Inputs,False,None)\n","  for n,prediction in enumerate(predictions):\n","      count+=1\n","      if len(prediction)<3:\n","        result=np.argmax(prediction)\n","        \n","        if result in Validation:\n","            correct+=1\n","      else:\n","        valid=Validation[0]\n","        if valid in np.argsort(prediction)[-2:]:\n","            correct+=1\n","\n","  return correct,count\n","eval_result()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Dev Accuracy 0.9195\n","Time taken: 885.4403672218323 secs\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5WgdPYs2qoyj","colab_type":"code","outputId":"04881875-e494-4f7b-d5c2-e8661c7df0b1","executionInfo":{"status":"ok","timestamp":1586859050548,"user_tz":-480,"elapsed":6138,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["para=['I had hot dog for breakfast.','I ate steak for dinner.']\n","question=['What did i have for dinner?','What did i eat in the morning?']\n","Inputs=[]i5hd\n","for q in question:\n","    temp=[q]+para\n","    Inputs.append(temp)\n","result=AnswerLocator(Inputs,False,None)\n","result"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[0.5007382 , 0.4992618 ],\n","       [0.50087184, 0.4991281 ]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"ay9y0AyWsdlR","colab_type":"code","outputId":"4fd34781-fd23-49a4-8aee-1a45e2ea3ee1","executionInfo":{"status":"ok","timestamp":1586100359108,"user_tz":240,"elapsed":2504,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["para=['I went to work in the morning and went home at night.','I like to eat chocolate, but I hate to eat bananas.']\n","question=['What did i do in the morning?','when did i go to work?','What do i hate to eat?']\n","Inputs=[]\n","for q in question:\n","    temp=[q]+para\n","    Inputs.append(temp)\n","AnswerLocator(Inputs,False,None)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n","array([[0.92415655, 0.0758434 ],\n","       [0.96577615, 0.03422388],\n","       [0.06499044, 0.93500954]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"pPz0uDKNtbaN","colab_type":"code","outputId":"e5d41817-c182-4022-a6a2-44690bad637f","executionInfo":{"status":"ok","timestamp":1586773038662,"user_tz":300,"elapsed":1065,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["para=[\"Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season.\",\\\n","       \"The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title.\",\\\n","       \"The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\",\n","       'As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.']\n","question=['Which NFL team represented the AFC at Super Bowl 50?',\\\n","          'Which NFL team represented the NFC at Super Bowl 50?',\\\n","          'What venue did Super Bowl 50 take place in?',\\\n","          'What team was the champion?']\n","Inputs=[]\n","for q in question:\n","    temp=[q]+para\n","    Inputs.append(temp)\n","result=AnswerLocator(Inputs,False,None)\n","result"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n","array([[0.33483383, 0.6187628 , 0.01326892, 0.03313452],\n","       [0.3255554 , 0.63913226, 0.01367904, 0.02163324],\n","       [0.24305443, 0.09530964, 0.4309794 , 0.2306565 ],\n","       [0.04987707, 0.59426653, 0.3273321 , 0.02852429]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"hHzzUqRLpOWM","colab_type":"code","outputId":"d03dc89d-8a0e-4353-df44-7123ccff057d","executionInfo":{"status":"ok","timestamp":1586955036691,"user_tz":-480,"elapsed":142206,"user":{"displayName":"Jason Kang","photoUrl":"","userId":"04894447894355605611"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["para=['A problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used.',\\\n","      'The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying the amount of resources needed to solve them, such as time and storage.',\\\n","      'Other complexity measures are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing).',\\\n","      'One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do.']\n","question=['What measure of a computational problem broadly defines the inherent difficulty of the solution?',\\\n","          'What method is used to intuitively assess or quantify the amount of resources required to solve a computational problem?',\\\n","          'What are two basic primary resources used to guage 、\n","        ',\\\n","          'What unit is measured to determine circuit complexity?']\n","Inputs=[]\n","for q in question:\n","    temp=[q]+para\n","    Inputs.append(temp)\n","result=AnswerLocator(Inputs,False,None)\n","result"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n","array([[0.9470038 , 0.025538  , 0.0069189 , 0.02053931],\n","       [0.01949034, 0.78748393, 0.12155607, 0.07146969],\n","       [0.03315064, 0.22308715, 0.65726006, 0.08650219],\n","       [0.03066365, 0.06795207, 0.8401124 , 0.06127184]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":29}]}]}